{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from mimic4_preprocess_util import *\n",
    "from preprocess_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess_util\n",
    "importlib.reload(preprocess_util)\n",
    "from preprocess_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_cutoff = 14  # Outcome threshold\n",
    "Org = 'MRSA' # Target organism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required paths\n",
    "# Base paths\n",
    "path_folder = \"/data/mnigo/MDR_projects/MRSA\"\n",
    "path_clean2 = \"/data/mnigo/MDR_projects/MRSA/MIMIC/clean_data_MRSA_v2.1/clean_mapped_data_\" + Org + \"/\" +  str(day_cutoff)+'days/'\n",
    "path_clean3 = path_clean2\n",
    "MMH_path = '/data/mnigo/MDR_projects/MRSA/clean_data_clean_diag_simple_location_ISOLMRSA/14days/'\n",
    "# Original Data\n",
    "path_MRSA = path_folder + \"/pytorch_ehr/Pytorch_EHR_Tutorial/Data_Prep/data/MIMIC/MRSA data/\"\n",
    "# Data Preparation\n",
    "prefix_date = '20220618_'\n",
    "label = 'label.csv'\n",
    "remove_list_file = 'remove_less_18.csv'\n",
    "verbose = True\n",
    "\n",
    "# Path for PytorchEHR\n",
    "sys.path.insert(0, path_folder + \"/pytorch_ehr/Pytorch_EHR_Tutorial/Data_Prep/\")\n",
    "# The typeFile\n",
    "typeFile = os.path.join(MMH_path, 'Mimic_PT_mortality_dp_v1.types')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to change the column names to fit pytoruch_ehr\n",
    "d_demographic = {'Study_ID_Combine': 'subject_id', 'Study_FIN_Combine': 'hadm_id', 'M_Admit Date & Time': 'admittime',\n",
    "                'M_Discharge Date & Time': 'dischtime', 'Person Location- Building (Admit)':'admit_building' ,\n",
    "                'Person Location- Facility (Admit)':'admit_facility', 'Person Location- Nurse Unit (Admit)':'admit_nurse_unit',\n",
    "                'Age- Years (Visit)': 'age', 'Ethnic Group-Curr': 'ethnicity', 'Language-Curr': 'language',\n",
    "                 'M_Deceased Date & Time-Curr': 'deathdate','Race-Curr': 'race', 'Sex-Curr': 'gender',\n",
    "                'ICD10 Diagnosis Code': 'icd_code', 'ICD10 Diagnosis Description': 'icd10_des',\n",
    "                 'M_Diagnosis Date & Time': 'chartdate', 'M_Check In Date/Time': 'chartdate', 'PostOp Diagnosis': 'postopdx',\n",
    "                'Scheduled Anesthesia Type': 'anethtype', 'Procedure Code': 'proc_code', 'M_Procedure Date and Time': 'chartdate',\n",
    "                'M_Drawn Date & Time': 'chartdate', 'M_Clinical Event End Date/Time': 'chartdate'}\n",
    "d_demographic2 = {'M_Local_System_ID': 'subject_id'}       \n",
    "dtypes = {'subject_id': str, 'Study_ID_Combine':str, 'Study_FIN_Combine': str}\n",
    "date_columns = ['chartdate', 'date']\n",
    "# Define prefixes for files\n",
    "prefixes = ['case_14days', 'control_14days', 'case_demographic2', 'control_demographic2', 'case_antibiotics_true2',\n",
    "            'control_antibiotics_true2', 'case_culture_result2', 'control_culture_result2',\n",
    "            'case_demographic3', 'control_demographic3', 'case_procedure', 'control_procedure',\n",
    "            'case_micro_order', 'control_micro_order', 'case_micro_order2', 'control_micro_order2',\n",
    "            'case_diagnosis', 'control_diagnosis', 'case_lab_order', 'control_lab_order',\n",
    "            'case_lab_result', 'control_lab_result', 'case_micro_sensitivity2', 'control_micro_sensitivity2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = pd.read_csv(path_MRSA + remove_list_file, dtype=str)\n",
    "remove_list = remove['subject_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful methods\n",
    "def load_data(file_path, prefix, dtypes, date_columns=None):\n",
    "    file_name = prefix + '.csv'\n",
    "    data = pd.read_csv(file_path + file_name, dtype=dtypes, parse_dates=date_columns)\n",
    "    if 'subject_id' in data.columns:\n",
    "        remove = pd.read_csv(path_MRSA + remove_list_file, dtype=str)\n",
    "        remove_list = remove['subject_id'].unique().tolist()\n",
    "        data = data[~data['subject_id'].isin(remove_list)]\n",
    "    #if date_columns:\n",
    "    #    data = date_change(data)\n",
    "    return data\n",
    "\n",
    "def filter_and_concat(dataframes, subjects_index, subjects_index2):\n",
    "    filtered_dataframes = [df[df['subject_id'].isin(subjects_index)] for df in dataframes]\n",
    "    filtered_dataframes2 = [df[df['subject_id'].isin(subjects_index2)] for df in dataframes]\n",
    "\n",
    "    return pd.concat(filtered_dataframes + filtered_dataframes2).dropna().drop_duplicates()\n",
    "\n",
    "def save_to_tsv(dataframe, file_path):\n",
    "    dataframe.to_csv(file_path, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_change(data):\n",
    "    data['chartdate'] = data['chartdate'].astype('datetime64')\n",
    "    data['date'] = data['chartdate'].dt.date\n",
    "    data['date'] = data['date'].astype('datetime64') \n",
    "    return data\n",
    "\n",
    "def check_terms(data, term):\n",
    "    return data[data['event_code'].isin(term)]\n",
    "\n",
    "def check_terms_l(data, term):\n",
    "    return data[data['event_code'].str.lower().str.contains('|'.join(term))]\n",
    "\n",
    "def check_terms_c(data, term):\n",
    "    return data[data['event_code'].str.contains('|'.join(term))]\n",
    "\n",
    "def extract_columns(data):\n",
    "    data = data[['subject_id', 'new_subject_id', 'date', 'event_code']]\n",
    "    data = data[~data['subject_id'].isin(remove_list)]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and prepare for the data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data using the function\n",
    "data_dict = {prefix: load_data(path_clean2, prefix, dtypes, date_columns) for prefix in prefixes}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the values from the dictionary\n",
    "values = list(data_dict.values())\n",
    "\n",
    "# Unpack data from the dictionary\n",
    "(case, cntrl, case_demo, cntrl_demo, case_abx, cntrl_abx, case_cx_results, cntrl_cx_results,\n",
    " case_demo3, cntrl_demo3, case_proc, cntrl_proc, case_order, cntrl_order,\n",
    " case_order2, cntrl_order2, case_dx, cntrl_dx, case_order_loc, cntrl_order_loc,\n",
    " case_order_result, cntrl_order_result, case_sensitivity, cntrl_sensitivity) = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [case_demo, cntrl_demo, case_dx, cntrl_dx, case_abx, cntrl_abx, \n",
    "              case_order_loc, cntrl_order_loc, case_order_result, cntrl_order_result, \n",
    "              case_sensitivity, cntrl_sensitivity, case_cx_results, cntrl_cx_results, \n",
    "              case_demo3, cntrl_demo3, case_order, cntrl_order, case_order2, cntrl_order2, \n",
    "              case_proc, cntrl_proc]\n",
    "\n",
    "for df in dataframes:\n",
    "    df = extract_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "case['mort']=1\n",
    "cntrl['mort']=0\n",
    "case['tte'] = case[str(day_cutoff)+'_'+ Org + '_positive_day'].str[:-4].astype(int)\n",
    "cntrl['tte'] = day_cutoff #.str[:-4].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>chartdate</th>\n",
       "      <th>event_code</th>\n",
       "      <th>date</th>\n",
       "      <th>new_subject_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19339920</td>\n",
       "      <td>2109-06-18 09:30:00</td>\n",
       "      <td>TEST_(STAT) Hep Bs Ag_Blood_0_Result Type$Nega...</td>\n",
       "      <td>2109-06-19</td>\n",
       "      <td>19339920_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19339920</td>\n",
       "      <td>2109-06-18 09:30:00</td>\n",
       "      <td>TEST_HBc Ab_Blood_0_Result Type$Negative</td>\n",
       "      <td>2109-06-19</td>\n",
       "      <td>19339920_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19339920</td>\n",
       "      <td>2109-06-18 09:30:00</td>\n",
       "      <td>TEST_Hep C Ab_Blood_0_Result Type$Negative</td>\n",
       "      <td>2109-06-19</td>\n",
       "      <td>19339920_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14982471</td>\n",
       "      <td>2110-06-09 08:40:00</td>\n",
       "      <td>TEST_Hep Bs Ab Immune Status (Qst)_Blood_0_Res...</td>\n",
       "      <td>2110-06-10</td>\n",
       "      <td>14982471_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14982471</td>\n",
       "      <td>2110-06-09 08:40:00</td>\n",
       "      <td>TEST_Hep C Ab_Blood_0_Result Type$Negative</td>\n",
       "      <td>2110-06-10</td>\n",
       "      <td>14982471_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12995</th>\n",
       "      <td>13774759</td>\n",
       "      <td>2203-11-21 15:43:00</td>\n",
       "      <td>TEST_CDC HIV 4th GEN_Blood_0_Result Type$Negative</td>\n",
       "      <td>2203-11-21</td>\n",
       "      <td>13774759_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12996</th>\n",
       "      <td>13774759</td>\n",
       "      <td>2203-11-21 15:43:00</td>\n",
       "      <td>TEST_(STAT) Hep Bs Ag_Blood_0_Result Type$Nega...</td>\n",
       "      <td>2203-11-22</td>\n",
       "      <td>13774759_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12997</th>\n",
       "      <td>13774759</td>\n",
       "      <td>2203-11-21 15:43:00</td>\n",
       "      <td>TEST_Hep C Ab_Blood_0_Result Type$Negative</td>\n",
       "      <td>2203-11-22</td>\n",
       "      <td>13774759_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12999</th>\n",
       "      <td>17370506</td>\n",
       "      <td>2197-11-07 10:40:00</td>\n",
       "      <td>TEST_Hep Bs Ab Immune Status (Qst)_Blood_0_Res...</td>\n",
       "      <td>2197-11-08</td>\n",
       "      <td>17370506_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13001</th>\n",
       "      <td>17370506</td>\n",
       "      <td>2197-11-07 10:40:00</td>\n",
       "      <td>TEST_Hep C Ab_Blood_0_Result Type$Negative</td>\n",
       "      <td>2197-11-08</td>\n",
       "      <td>17370506_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject_id           chartdate  \\\n",
       "0       19339920 2109-06-18 09:30:00   \n",
       "1       19339920 2109-06-18 09:30:00   \n",
       "2       19339920 2109-06-18 09:30:00   \n",
       "16      14982471 2110-06-09 08:40:00   \n",
       "17      14982471 2110-06-09 08:40:00   \n",
       "...          ...                 ...   \n",
       "12995   13774759 2203-11-21 15:43:00   \n",
       "12996   13774759 2203-11-21 15:43:00   \n",
       "12997   13774759 2203-11-21 15:43:00   \n",
       "12999   17370506 2197-11-07 10:40:00   \n",
       "13001   17370506 2197-11-07 10:40:00   \n",
       "\n",
       "                                              event_code       date  \\\n",
       "0      TEST_(STAT) Hep Bs Ag_Blood_0_Result Type$Nega... 2109-06-19   \n",
       "1               TEST_HBc Ab_Blood_0_Result Type$Negative 2109-06-19   \n",
       "2             TEST_Hep C Ab_Blood_0_Result Type$Negative 2109-06-19   \n",
       "16     TEST_Hep Bs Ab Immune Status (Qst)_Blood_0_Res... 2110-06-10   \n",
       "17            TEST_Hep C Ab_Blood_0_Result Type$Negative 2110-06-10   \n",
       "...                                                  ...        ...   \n",
       "12995  TEST_CDC HIV 4th GEN_Blood_0_Result Type$Negative 2203-11-21   \n",
       "12996  TEST_(STAT) Hep Bs Ag_Blood_0_Result Type$Nega... 2203-11-22   \n",
       "12997         TEST_Hep C Ab_Blood_0_Result Type$Negative 2203-11-22   \n",
       "12999  TEST_Hep Bs Ab Immune Status (Qst)_Blood_0_Res... 2197-11-08   \n",
       "13001         TEST_Hep C Ab_Blood_0_Result Type$Negative 2197-11-08   \n",
       "\n",
       "      new_subject_id  \n",
       "0         19339920_1  \n",
       "1         19339920_1  \n",
       "2         19339920_1  \n",
       "16        14982471_5  \n",
       "17        14982471_5  \n",
       "...              ...  \n",
       "12995    13774759_12  \n",
       "12996    13774759_12  \n",
       "12997    13774759_12  \n",
       "12999     17370506_5  \n",
       "13001     17370506_5  \n",
       "\n",
       "[9613 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types_d2=pickle.load(open(typeFile, 'rb'), encoding='bytes')\n",
    "types_d_rev_org = dict(zip(types_d2.values(),types_d2.keys()))\n",
    "dict_list = list(types_d2.keys())\n",
    "dict_list = list(set(dict_list))\n",
    "dict_df = pd.DataFrame(dict_list)\n",
    "dict_df = dict_df[~dict_df[0].str.contains('ADM_DX')]\n",
    "check_terms_l(case_order_result, ['negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restructure ICD codes \n",
    "case_dx = ICD_restructure(case_dx, dict_df)\n",
    "cntrl_dx = ICD_restructure(cntrl_dx, dict_df)\n",
    "# Restructure procedures\n",
    "case_proc = Proc_restructure(case_proc, dict_df)\n",
    "cntrl_proc = Proc_restructure(cntrl_proc, dict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_to_check = [case_demo, cntrl_demo, case_abx, cntrl_abx, case_demo3, cntrl_demo3, \n",
    "                       case_order, cntrl_order, case_order2, cntrl_order2, case_order_loc, \n",
    "                       cntrl_order_loc, case_order_result, cntrl_order_result, case_sensitivity, \n",
    "                       cntrl_sensitivity, case_cx_results, cntrl_cx_results]\n",
    "\n",
    "def apply_check_terms(df, columns):\n",
    "    return check_terms(df, columns)\n",
    "\n",
    "for df in dataframes_to_check:\n",
    "    df = apply_check_terms(df, dict_df[0].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split datasets into train, valid, and test sets\n",
    "train_mrns_case, valid_mrns_case, test_mrns_case = split(case)\n",
    "temp = cntrl[~cntrl['subject_id'].isin(case['subject_id'].unique())]\n",
    "train_mrns_cnt, valid_mrns_cnt, test_mrns_cnt = split(temp)\n",
    "# Concatenate MRNs for train, valid, and test sets\n",
    "train_mrns = train_mrns_case.append(train_mrns_cnt)\n",
    "valid_mrns = valid_mrns_case.append(valid_mrns_cnt)\n",
    "test_mrns = test_mrns_case.append(test_mrns_cnt)\n",
    "# Create copies of MRNs\n",
    "train_mrns2 = train_mrns.copy()\n",
    "valid_mrns2 = valid_mrns.copy()\n",
    "test_mrns2 = test_mrns.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_indices = {\n",
    "    'train': (train_mrns[1].unique(), train_mrns2[1].unique()),\n",
    "    'valid': (valid_mrns[1].unique(), valid_mrns2[1].unique()),\n",
    "    'test': (test_mrns[1].unique(), test_mrns2[1].unique())\n",
    "}\n",
    "\n",
    "for set_type, (index, index2) in subjects_indices.items():\n",
    "    dataframes_to_concat = [case_demo, cntrl_demo, case_demo3, cntrl_demo3, case_dx, cntrl_dx,\n",
    "                            case_abx, cntrl_abx, case_proc, cntrl_proc, case_order_loc,\n",
    "                            cntrl_order_loc, case_order, cntrl_order, case_order2, cntrl_order2,\n",
    "                            case_order_result, cntrl_order_result, case_cx_results, cntrl_cx_results,\n",
    "                            case_sensitivity, cntrl_sensitivity]\n",
    "\n",
    "    concatenated_dataframe = filter_and_concat(dataframes_to_concat, index, index2)\n",
    "    save_to_tsv(concatenated_dataframe, f'{path_clean3}/MHH_PT_data_dp2_{set_type}.tsv')\n",
    "\n",
    "    case_temp = case[case['subject_id'].isin(index)][['subject_id', 'new_subject_id', 'mort', 'tte']].drop_duplicates()\n",
    "    cntrl_temp = cntrl[cntrl['subject_id'].isin(index2)][['subject_id', 'new_subject_id', 'mort', 'tte']].drop_duplicates()\n",
    "\n",
    "    outcome_labels = pd.concat([case_temp, cntrl_temp]).dropna()\n",
    "    save_to_tsv(outcome_labels, f'{path_clean3}/MHH_PT_outcome_labels2_{set_type}.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The actual data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Proprocess data into pickled list\n",
    "sys.path.insert(0, path_folder + \"/pytorch_ehr/Pytorch_EHR_Tutorial/Data_Prep/\")\n",
    "from preprocess_outcomes  import dump_split_process_data\n",
    "from preprocess_outcomes  import *\n",
    "\n",
    "dataFile  = path_clean3+'/MHH_PT_data_dp2_'\n",
    "labelFile = path_clean3+'/MHH_PT_outcome_labels2_' \n",
    "MMH_path = '/data/mnigo/MDR_projects/MRSA/clean_data_clean_diag_simple_location_ISOLMRSA/14days/'\n",
    "typeFile = MMH_path +'Mimic_PT_mortality_dp_v1.types'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dump_split_process_data('train', dataFile, labelFile, typeFile ,path_clean3+'/Mimic_PT_mortality_dp_v2' , 'NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "typeFile = path_clean3+ 'Mimic_PT_mortality_dp_v2.types'\n",
    "dump_split_process_data('valid', dataFile, labelFile, typeFile ,path_clean3+'/Mimic_PT_mortality_dp_v2' , 'NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dump_split_process_data('test', dataFile, labelFile, typeFile ,path_clean3+'/Mimic_PT_mortality_dp_v2' , 'NA')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
